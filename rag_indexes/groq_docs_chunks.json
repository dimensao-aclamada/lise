[
  "Groq is fast inference for AI builders skip to content Groq Products Arrow pointing down Products Overview GroqCloud™ Platform Fast, affordable Al inference on-demand, powered by Groq LPUs. GroqRack™ Cluster On-prem Al inference for your data center, powered by Groq LPUs. Enterprise Arrow pointing down Contact Sales Developers Arrow pointing down Free API key Quickstart Community Demos Resources Arrow pointing down Blog Case Studies News Videos Whitepapers Pricing About Arrow pointing down About Groq Announcements Team Careers News Contact Us Start Building Menu Toggle Main Navigation Close icon Close mobile navigation Products Arrow pointing down Products Overview GroqCloud™ Platform Fast, affordable Al inference on-demand, powered by Groq LPUs. GroqRack™ Cluster On-prem Al inference for your data center, powered by Groq LPUs. Enterprise Arrow pointing down Contact Sales Developers Arrow pointing down Free API key Quickstart Community Demos Resources Arrow pointing down Blog Case Studies News Videos Whitepapers Pricing About Arrow pointing down About Groq Announcements Team Careers News Contact Us Groq Community Discord Twitter YouTube Thread LinkedIn Instagram The Infrastructure For Inference Purpose-built for speed, quality, cost, and scale. Start Building Join Over 1.9 Million Developers and Teams Try Groq For Free Designed for Inference. Not Adapted for It. Inference is where AI goes to work. Our custom LPU™ is built for this phase—developed in the U.S. with a resilient supply chain for consistent performance at scale. It powers GroqCloud™, a full-stack platform for fast, affordable, production-ready inference. Start Building Watch the Demo Jonathan Ross CEO & Founder Run More. Spend Less. No Compromise. Independent 3rd party benchmarks from ArtificialAnalysis.ai Unmatched Price Performance Groq provides the lowest cost per token, even as usage grows, without sacrificing speed, quality, or control. See Our Pricing Independent 3rd party benchmarks from ArtificialAnalysis.ai Speed at any Scale Other inference slows down when the real work starts. Groq has sub-millisecond latency that stays consistent across traffic, regions, and workloads. Explore Benchmarks Model Quality You Can Trust Groq’s architecture is built to preserve model quality at every size—from compact and voice models to large-scale MoEs—consistently and at production scale. View Models Featured Groq Applauds Trump Administration’s AI Action Plan, Accelerates Global Deployment of the American AI Stack July 23, 2025 Groq Launches European Data Center Footprint in Helsinki, Finland July 6, 2025 Build Fast Seamlessly integrate Groq starting with just a few lines of code Try Groq for Free Groq Groq was established in 2016 for one thing: inference. Products Pricing Products Overview GroqCloud™ Platform GroqRack™ Cluster Enterprise Enterprise Access Developers Free API Key Start Building Groq Libraries Demos Resources Blog Case Studies News Videos Whitepapers About About Groq Announcements Team Careers News Contact Us Terms & Policies Privacy Policy Trust Center Terms of Use GroqCloud Terms Security Trademark Policy Cookie Policy © 2025 Groq, Inc. , All rights reserved. Groq Community Discord Twitter YouTube Thread LinkedIn Instagram",
  "one thing: inference. Products Pricing Products Overview GroqCloud™ Platform GroqRack™ Cluster Enterprise Enterprise Access Developers Free API Key Start Building Groq Libraries Demos Resources Blog Case Studies News Videos Whitepapers About About Groq Announcements Team Careers News Contact Us Terms & Policies Privacy Policy Trust Center Terms of Use GroqCloud Terms Security Trademark Policy Cookie Policy © 2025 Groq, Inc. , All rights reserved. Groq Community Discord Twitter YouTube Thread LinkedIn Instagram",
  "Groq is fast inference for AI builders skip to content Groq Products Arrow pointing down Products Overview GroqCloud™ Platform Fast, affordable Al inference on-demand, powered by Groq LPUs. GroqRack™ Cluster On-prem Al inference for your data center, powered by Groq LPUs. Enterprise Arrow pointing down Contact Sales Developers Arrow pointing down Free API key Quickstart Community Demos Resources Arrow pointing down Blog Case Studies News Videos Whitepapers Pricing About Arrow pointing down About Groq Announcements Team Careers News Contact Us Start Building Menu Toggle Main Navigation Close icon Close mobile navigation Products Arrow pointing down Products Overview GroqCloud™ Platform Fast, affordable Al inference on-demand, powered by Groq LPUs. GroqRack™ Cluster On-prem Al inference for your data center, powered by Groq LPUs. Enterprise Arrow pointing down Contact Sales Developers Arrow pointing down Free API key Quickstart Community Demos Resources Arrow pointing down Blog Case Studies News Videos Whitepapers Pricing About Arrow pointing down About Groq Announcements Team Careers News Contact Us Groq Community Discord Twitter YouTube Thread LinkedIn Instagram The Infrastructure For Inference Purpose-built for speed, quality, cost, and scale. Start Building Join Over 1.9 Million Developers and Teams Try Groq For Free Designed for Inference. Not Adapted for It. Inference is where AI goes to work. Our custom LPU™ is built for this phase—developed in the U.S. with a resilient supply chain for consistent performance at scale. It powers GroqCloud™, a full-stack platform for fast, affordable, production-ready inference. Start Building Watch the Demo Jonathan Ross CEO & Founder Run More. Spend Less. No Compromise. Independent 3rd party benchmarks from ArtificialAnalysis.ai Unmatched Price Performance Groq provides the lowest cost per token, even as usage grows, without sacrificing speed, quality, or control. See Our Pricing Independent 3rd party benchmarks from ArtificialAnalysis.ai Speed at any Scale Other inference slows down when the real work starts. Groq has sub-millisecond latency that stays consistent across traffic, regions, and workloads. Explore Benchmarks Model Quality You Can Trust Groq’s architecture is built to preserve model quality at every size—from compact and voice models to large-scale MoEs—consistently and at production scale. View Models Featured Groq Applauds Trump Administration’s AI Action Plan, Accelerates Global Deployment of the American AI Stack July 23, 2025 Groq Launches European Data Center Footprint in Helsinki, Finland July 6, 2025 Build Fast Seamlessly integrate Groq starting with just a few lines of code Try Groq for Free Groq Groq was established in 2016 for one thing: inference. Products Pricing Products Overview GroqCloud™ Platform GroqRack™ Cluster Enterprise Enterprise Access Developers Free API Key Start Building Groq Libraries Demos Resources Blog Case Studies News Videos Whitepapers About About Groq Announcements Team Careers News Contact Us Terms & Policies Privacy Policy Trust Center Terms of Use GroqCloud Terms Security Trademark Policy Cookie Policy © 2025 Groq, Inc. , All rights reserved. Groq Community Discord Twitter YouTube Thread LinkedIn Instagram",
  "one thing: inference. Products Pricing Products Overview GroqCloud™ Platform GroqRack™ Cluster Enterprise Enterprise Access Developers Free API Key Start Building Groq Libraries Demos Resources Blog Case Studies News Videos Whitepapers About About Groq Announcements Team Careers News Contact Us Terms & Policies Privacy Policy Trust Center Terms of Use GroqCloud Terms Security Trademark Policy Cookie Policy © 2025 Groq, Inc. , All rights reserved. Groq Community Discord Twitter YouTube Thread LinkedIn Instagram",
  "Groq is fast inference for AI builders skip to content Groq Products Arrow pointing down Products Overview GroqCloud™ Platform Fast, affordable Al inference on-demand, powered by Groq LPUs. GroqRack™ Cluster On-prem Al inference for your data center, powered by Groq LPUs. Enterprise Arrow pointing down Contact Sales Developers Arrow pointing down Free API key Quickstart Community Demos Resources Arrow pointing down Blog Case Studies News Videos Whitepapers Pricing About Arrow pointing down About Groq Announcements Team Careers News Contact Us Start Building Menu Toggle Main Navigation Close icon Close mobile navigation Products Arrow pointing down Products Overview GroqCloud™ Platform Fast, affordable Al inference on-demand, powered by Groq LPUs. GroqRack™ Cluster On-prem Al inference for your data center, powered by Groq LPUs. Enterprise Arrow pointing down Contact Sales Developers Arrow pointing down Free API key Quickstart Community Demos Resources Arrow pointing down Blog Case Studies News Videos Whitepapers Pricing About Arrow pointing down About Groq Announcements Team Careers News Contact Us Groq Community Discord Twitter YouTube Thread LinkedIn Instagram The Infrastructure For Inference Purpose-built for speed, quality, cost, and scale. Start Building Join Over 1.9 Million Developers and Teams Try Groq For Free Designed for Inference. Not Adapted for It. Inference is where AI goes to work. Our custom LPU™ is built for this phase—developed in the U.S. with a resilient supply chain for consistent performance at scale. It powers GroqCloud™, a full-stack platform for fast, affordable, production-ready inference. Start Building Watch the Demo Jonathan Ross CEO & Founder Run More. Spend Less. No Compromise. Independent 3rd party benchmarks from ArtificialAnalysis.ai Unmatched Price Performance Groq provides the lowest cost per token, even as usage grows, without sacrificing speed, quality, or control. See Our Pricing Independent 3rd party benchmarks from ArtificialAnalysis.ai Speed at any Scale Other inference slows down when the real work starts. Groq has sub-millisecond latency that stays consistent across traffic, regions, and workloads. Explore Benchmarks Model Quality You Can Trust Groq’s architecture is built to preserve model quality at every size—from compact and voice models to large-scale MoEs—consistently and at production scale. View Models Featured Groq Applauds Trump Administration’s AI Action Plan, Accelerates Global Deployment of the American AI Stack July 23, 2025 Groq Launches European Data Center Footprint in Helsinki, Finland July 6, 2025 Build Fast Seamlessly integrate Groq starting with just a few lines of code Try Groq for Free Groq Groq was established in 2016 for one thing: inference. Products Pricing Products Overview GroqCloud™ Platform GroqRack™ Cluster Enterprise Enterprise Access Developers Free API Key Start Building Groq Libraries Demos Resources Blog Case Studies News Videos Whitepapers About About Groq Announcements Team Careers News Contact Us Terms & Policies Privacy Policy Trust Center Terms of Use GroqCloud Terms Security Trademark Policy Cookie Policy © 2025 Groq, Inc. , All rights reserved. Groq Community Discord Twitter YouTube Thread LinkedIn Instagram",
  "one thing: inference. Products Pricing Products Overview GroqCloud™ Platform GroqRack™ Cluster Enterprise Enterprise Access Developers Free API Key Start Building Groq Libraries Demos Resources Blog Case Studies News Videos Whitepapers About About Groq Announcements Team Careers News Contact Us Terms & Policies Privacy Policy Trust Center Terms of Use GroqCloud Terms Security Trademark Policy Cookie Policy © 2025 Groq, Inc. , All rights reserved. Groq Community Discord Twitter YouTube Thread LinkedIn Instagram",
  "Products | Groq is fast inference for AI builders skip to content Groq Products Arrow pointing down Products Overview GroqCloud™ Platform Fast, affordable Al inference on-demand, powered by Groq LPUs. GroqRack™ Cluster On-prem Al inference for your data center, powered by Groq LPUs. Enterprise Arrow pointing down Contact Sales Developers Arrow pointing down Free API key Quickstart Community Demos Resources Arrow pointing down Blog Case Studies News Videos Whitepapers Pricing About Arrow pointing down About Groq Announcements Team Careers News Contact Us Start Building Menu Toggle Main Navigation Close icon Close mobile navigation Products Arrow pointing down Products Overview GroqCloud™ Platform Fast, affordable Al inference on-demand, powered by Groq LPUs. GroqRack™ Cluster On-prem Al inference for your data center, powered by Groq LPUs. Enterprise Arrow pointing down Contact Sales Developers Arrow pointing down Free API key Quickstart Community Demos Resources Arrow pointing down Blog Case Studies News Videos Whitepapers Pricing About Arrow pointing down About Groq Announcements Team Careers News Contact Us Groq Community Discord Twitter YouTube Thread LinkedIn Instagram Faster. Better Value. More Efficient. Our custom LPU is built for inference—developed in the U.S. with a resilient supply chain for consistent performance at scale. The LPU powers both GroqCloud, a full-stack platform for fast, affordable, production-ready inference, as well as GroqRack Compute Clusters, which are ideal for enterprises needing on-prem solutions for their own cloud or AI Compute Center. GroqCloud™ Platform GroqCloud™ Platform delivers fast AI inference easily and at scale via our Developer Console . Available as an on-demand public cloud as well as private and co-cloud instances. Learn more GroqRack™ Cluster Take your own cloud or AI Compute Center to the next level with on-prem deployments of GroqRack compute cluster delivering fast AI Inference. Learn more Groq Speed Is Instant Groq Advantages Viable GenAI use cases are hindered by the inference speed of GPUs. By optimizing compute density, memory bandwidth, and scalability, LPUs overcome this bottleneck and deliver ultra-low latency inference, unlocking a new class of use cases. Explore Benchmarks Affordability GPUs are ideal for training models, but not inference, making launching and scaling many AI applications economically infeasible. Groq offers a win-win solution: record-breaking speed at competitive rates. Additionally, the Groq architecture requires no external switches, meaning CAPEX for on-prem deployments Groq is spent on compute, not network infrastructure. Source: McKinsey. Energy Efficiency At an architectural level, the LPU is up to 10X more energy efficient than other systems. This is because Groq employs a fundamentally different, much more efficient approach to inference computing whether in GroqCloud platform or a GroqRack cluster. Read more about Groq energy efficiency Sign up for Groq updates Groq Groq was established in 2016 for one thing: inference. Products Pricing Products Overview GroqCloud™ Platform GroqRack™ Cluster Enterprise Enterprise Access Developers Free API Key Start Building Groq Libraries Demos Resources Blog Case Studies News Videos Whitepapers About About Groq Announcements Team Careers News Contact Us Terms & Policies Privacy Policy Trust Center Terms of Use GroqCloud Terms Security Trademark Policy Cookie Policy",
  "than other systems. This is because Groq employs a fundamentally different, much more efficient approach to inference computing whether in GroqCloud platform or a GroqRack cluster. Read more about Groq energy efficiency Sign up for Groq updates Groq Groq was established in 2016 for one thing: inference. Products Pricing Products Overview GroqCloud™ Platform GroqRack™ Cluster Enterprise Enterprise Access Developers Free API Key Start Building Groq Libraries Demos Resources Blog Case Studies News Videos Whitepapers About About Groq Announcements Team Careers News Contact Us Terms & Policies Privacy Policy Trust Center Terms of Use GroqCloud Terms Security Trademark Policy Cookie Policy © 2025 Groq, Inc. , All rights reserved. Groq Community Discord Twitter YouTube Thread LinkedIn Instagram",
  "GroqCloud | Groq is fast inference for AI builders skip to content Groq Products Arrow pointing down Products Overview GroqCloud™ Platform Fast, affordable Al inference on-demand, powered by Groq LPUs. GroqRack™ Cluster On-prem Al inference for your data center, powered by Groq LPUs. Enterprise Arrow pointing down Contact Sales Developers Arrow pointing down Free API key Quickstart Community Demos Resources Arrow pointing down Blog Case Studies News Videos Whitepapers Pricing About Arrow pointing down About Groq Announcements Team Careers News Contact Us Start Building Menu Toggle Main Navigation Close icon Close mobile navigation Products Arrow pointing down Products Overview GroqCloud™ Platform Fast, affordable Al inference on-demand, powered by Groq LPUs. GroqRack™ Cluster On-prem Al inference for your data center, powered by Groq LPUs. Enterprise Arrow pointing down Contact Sales Developers Arrow pointing down Free API key Quickstart Community Demos Resources Arrow pointing down Blog Case Studies News Videos Whitepapers Pricing About Arrow pointing down About Groq Announcements Team Careers News Contact Us Groq Community Discord Twitter YouTube Thread LinkedIn Instagram Build Fast. Easy Access to Fast AI Inference. Migrate to Groq from other providers like OpenAI and get started by changing three lines of code With our OpenAI endpoint compatibility, simply set OPENAI_API_KEY to your Groq API Key. Set the base URL. Choose your model and run! Start building now Try GroqCloud™ Platform Today GroqCloud platform provides fast and affordable inference. Available as public, private, and co-cloud instances, GroqCloud platform redefines real-time. Unlock a new set of use cases by running your AI applications instantly. Get started for free today and join the 1M+ developers already building on GroqCloud platform. Try GroqChat Get free API key Agentic Ready Seamlessly integrate tools, leverage real-time streaming, and connect to external sources to empower agents with enhanced intelligence. Transform natural language into actionable API calls and build dynamic, real-time workflows, driving efficiency and innovation. Multiple Languages Supported Build applications with Groq API using the language of your choice with support for curl, JavaScript, Python, and JSON. Industry Standard Frameworks and Integrations Build cutting-edge applications leveraging industry-leading frameworks and integrations like LangChain, Llamaindex, CrewAI, Vercel AI SDK, and more. Create context-aware apps and enjoy real-time streamed UIs for dynamic, responsive applications that adapt to user needs. Learn more about GroqCloud platform integrations . Leading GenAI Models Take advantage of fast AI inference performance for leading GenAI models across text, audio, and vision modalities from providers like Meta, DeepSeek, Qwen, Mistral, Google, OpenAI, and more. No-code Developer Playground Start exploring Groq API and featured models without writing a single line of code on the GroqCloud Developer Console. GroqCloud Developer Console Pricing You shouldn’t have to pay large upfront costs to start generating tokens. The Groq on-demand tokens-as-a-service model is simple. You pay as you go for the tokens consumed without any upfront costs. Explore our package and pricing options . Enterprise API Solutions Our solutions are designed to meet custom and large scale needs, offering enterprise-grade capacity and dedicated support. To learn more, please fill",
  "providers like Meta, DeepSeek, Qwen, Mistral, Google, OpenAI, and more. No-code Developer Playground Start exploring Groq API and featured models without writing a single line of code on the GroqCloud Developer Console. GroqCloud Developer Console Pricing You shouldn’t have to pay large upfront costs to start generating tokens. The Groq on-demand tokens-as-a-service model is simple. You pay as you go for the tokens consumed without any upfront costs. Explore our package and pricing options . Enterprise API Solutions Our solutions are designed to meet custom and large scale needs, offering enterprise-grade capacity and dedicated support. To learn more, please fill out our brief form and a member from our Sales team will reach out to connect on your inference needs. Sign up for Groq updates Groq Groq was established in 2016 for one thing: inference. Products Pricing Products Overview GroqCloud™ Platform GroqRack™ Cluster Enterprise Enterprise Access Developers Free API Key Start Building Groq Libraries Demos Resources Blog Case Studies News Videos Whitepapers About About Groq Announcements Team Careers News Contact Us Terms & Policies Privacy Policy Trust Center Terms of Use GroqCloud Terms Security Trademark Policy Cookie Policy © 2025 Groq, Inc. , All rights reserved. Groq Community Discord Twitter YouTube Thread LinkedIn Instagram",
  "GroqRack | Groq is fast inference for AI builders skip to content Groq Products Arrow pointing down Products Overview GroqCloud™ Platform Fast, affordable Al inference on-demand, powered by Groq LPUs. GroqRack™ Cluster On-prem Al inference for your data center, powered by Groq LPUs. Enterprise Arrow pointing down Contact Sales Developers Arrow pointing down Free API key Quickstart Community Demos Resources Arrow pointing down Blog Case Studies News Videos Whitepapers Pricing About Arrow pointing down About Groq Announcements Team Careers News Contact Us Start Building Menu Toggle Main Navigation Close icon Close mobile navigation Products Arrow pointing down Products Overview GroqCloud™ Platform Fast, affordable Al inference on-demand, powered by Groq LPUs. GroqRack™ Cluster On-prem Al inference for your data center, powered by Groq LPUs. Enterprise Arrow pointing down Contact Sales Developers Arrow pointing down Free API key Quickstart Community Demos Resources Arrow pointing down Blog Case Studies News Videos Whitepapers Pricing About Arrow pointing down About Groq Announcements Team Careers News Contact Us Groq Community Discord Twitter YouTube Thread LinkedIn Instagram GroqRack™ Compute Cluster Take your own cloud or AI Compute Center to the next level with on-prem deployments. Groq LPU™ AI inference technology is available in various interconnected rack configurations to meet the needs of your preferred model sizes. Download Brief Groq On-prem Deployment Advantages Plug & Play Data Center Deployment With no exotic cooling or power requirements, deploying Groq systems requires no major overhaul to your existing data center infrastructure. Lower Costs & Footprint With routing built into the LPU, your dollar and data center space go towards what matters – compute – instead of the high overhead costs of networking infrastructure. Available North American-based Supply Groq currently has available supply, ready to get you up and running quickly with LPU AI inference technology that is designed and manufactured in North America. The Groq LPU Building Blocks The Groq LPU is a scalable software and hardware solution, with our compiler defining the LPU architecture, which is the basis of our systems. While Groq does not sell individual nodes, cards, or chips, our customers can access the LPU via GroqCloud platform and our on-prem solutions. Learn more about each system component below. Featuring eight compute plus one redundant GroqNode™ servers, GroqRack cluster provides an extensible deterministic LPU network with with an end-to-end latency of only 1.6µs for a single rack. How the LPU Is Different Than the GPU Groq LPU AI inference technology is fundamentally different from a GPU, which was originally designed for graphics processing. Groq Compiler is in control, and not secondary to hardware. Compute and memory are co-located on the chip, eliminating resource bottlenecks. Kernel-less compiler makes it easy and fast to compile new models. No caches and switches means seamless scalability. Leading GenAI Models Take advantage of fast AI inference performance for leading GenAI models across text, audio, and vision modalities from providers like Meta, DeepSeek, Qwen, Mistral, Google, OpenAI, and more. Sign up for Groq updates Groq Groq was established in 2016 for one thing:",
  "AI inference technology is fundamentally different from a GPU, which was originally designed for graphics processing. Groq Compiler is in control, and not secondary to hardware. Compute and memory are co-located on the chip, eliminating resource bottlenecks. Kernel-less compiler makes it easy and fast to compile new models. No caches and switches means seamless scalability. Leading GenAI Models Take advantage of fast AI inference performance for leading GenAI models across text, audio, and vision modalities from providers like Meta, DeepSeek, Qwen, Mistral, Google, OpenAI, and more. Sign up for Groq updates Groq Groq was established in 2016 for one thing: inference. Products Pricing Products Overview GroqCloud™ Platform GroqRack™ Cluster Enterprise Enterprise Access Developers Free API Key Start Building Groq Libraries Demos Resources Blog Case Studies News Videos Whitepapers About About Groq Announcements Team Careers News Contact Us Terms & Policies Privacy Policy Trust Center Terms of Use GroqCloud Terms Security Trademark Policy Cookie Policy © 2025 Groq, Inc. , All rights reserved. Groq Community Discord Twitter YouTube Thread LinkedIn Instagram",
  "Enterprise Access | Groq is fast inference for AI builders skip to content Groq Products Arrow pointing down Products Overview GroqCloud™ Platform Fast, affordable Al inference on-demand, powered by Groq LPUs. GroqRack™ Cluster On-prem Al inference for your data center, powered by Groq LPUs. Enterprise Arrow pointing down Contact Sales Developers Arrow pointing down Free API key Quickstart Community Demos Resources Arrow pointing down Blog Case Studies News Videos Whitepapers Pricing About Arrow pointing down About Groq Announcements Team Careers News Contact Us Start Building Menu Toggle Main Navigation Close icon Close mobile navigation Products Arrow pointing down Products Overview GroqCloud™ Platform Fast, affordable Al inference on-demand, powered by Groq LPUs. GroqRack™ Cluster On-prem Al inference for your data center, powered by Groq LPUs. Enterprise Arrow pointing down Contact Sales Developers Arrow pointing down Free API key Quickstart Community Demos Resources Arrow pointing down Blog Case Studies News Videos Whitepapers Pricing About Arrow pointing down About Groq Announcements Team Careers News Contact Us Groq Community Discord Twitter YouTube Thread LinkedIn Instagram Enterprise Access Fast AI Inference with Deployment Optionality Enterprise API Solutions GroqCloud™ provides fast and affordable inference, powered by our LPU-based AI infrastructure. Our solutions are designed to meet custom and large scale needs, offering enterprise-grade capacity and dedicated support. To learn more, please fill out our brief form and a member from our Sales team will reach out to connect on your inference needs. Dev Tier Self-serve Are you looking for pay-as-you-go, on-demand access to GroqCloud? You can now upgrade to our Developer Tier yourself. It’s perfect for developers and startups looking to scale up as you grow. Once you’ve signed up, get access to: A free API key The Groq API Cookbook Our Console Quickstart guide Learn more about our on-demand model pricing here . Groq Groq was established in 2016 for one thing: inference. Products Pricing Products Overview GroqCloud™ Platform GroqRack™ Cluster Enterprise Enterprise Access Developers Free API Key Start Building Groq Libraries Demos Resources Blog Case Studies News Videos Whitepapers About About Groq Announcements Team Careers News Contact Us Terms & Policies Privacy Policy Trust Center Terms of Use GroqCloud Terms Security Trademark Policy Cookie Policy © 2025 Groq, Inc. , All rights reserved. Groq Community Discord Twitter YouTube Thread LinkedIn Instagram",
  "Demos | Groq is fast inference for AI builders skip to content Groq Products Arrow pointing down Products Overview GroqCloud™ Platform Fast, affordable Al inference on-demand, powered by Groq LPUs. GroqRack™ Cluster On-prem Al inference for your data center, powered by Groq LPUs. Enterprise Arrow pointing down Contact Sales Developers Arrow pointing down Free API key Quickstart Community Demos Resources Arrow pointing down Blog Case Studies News Videos Whitepapers Pricing About Arrow pointing down About Groq Announcements Team Careers News Contact Us Start Building Menu Toggle Main Navigation Close icon Close mobile navigation Products Arrow pointing down Products Overview GroqCloud™ Platform Fast, affordable Al inference on-demand, powered by Groq LPUs. GroqRack™ Cluster On-prem Al inference for your data center, powered by Groq LPUs. Enterprise Arrow pointing down Contact Sales Developers Arrow pointing down Free API key Quickstart Community Demos Resources Arrow pointing down Blog Case Studies News Videos Whitepapers Pricing About Arrow pointing down About Groq Announcements Team Careers News Contact Us Groq Community Discord Twitter YouTube Thread LinkedIn Instagram Demos Chris Ho Project BlogWizard Create blogs from video or audio files instantly using AI powered by Groq. Soami Kapadia Project Media QA Use AI to summarize and ask questions about online media content. Benjamin Klieger Project Infinite Bookshelf Generate entire books in seconds using AI powered by Groq. Project Iniciopedia Custom tailored lesson plans / learning tree journey powered by Groq and generated in real-time. Project Pictollama Use Llama 3.2 vision to guess what you are drawing in real time. Project Stream of Thought Control AI with your voice to draft emails, generate prompts, create social media posts, and more within your workflow. Benjamin Klieger Project Scribe Wizard Generate organized notes from audio in a minute using AI powered by Groq. Soami Kapadia Project Agent Remix Agentic workflow configuration framework powered by Groq Benjamin Klieger Project StockBot Lightning fast AI chatbot that responds with live interactive stock charts, financials, news, screeners, and more. Project Front Page Get the latest Financial (and other) news with LLMs enabled with real-time contextual knowledge. Soami Kapadia Project Voice Real-time speech-to-text transcription and refinement powered by Groq. Groq Groq was established in 2016 for one thing: inference. Products Pricing Products Overview GroqCloud™ Platform GroqRack™ Cluster Enterprise Enterprise Access Developers Free API Key Start Building Groq Libraries Demos Resources Blog Case Studies News Videos Whitepapers About About Groq Announcements Team Careers News Contact Us Terms & Policies Privacy Policy Trust Center Terms of Use GroqCloud Terms Security Trademark Policy Cookie Policy © 2025 Groq, Inc. , All rights reserved. Groq Community Discord Twitter YouTube Thread LinkedIn Instagram",
  "& Policies Privacy Policy Trust Center Terms of Use GroqCloud Terms Security Trademark Policy Cookie Policy © 2025 Groq, Inc. , All rights reserved. Groq Community Discord Twitter YouTube Thread LinkedIn Instagram",
  "Blog | Groq is fast inference for AI builders skip to content Groq Products Arrow pointing down Products Overview GroqCloud™ Platform Fast, affordable Al inference on-demand, powered by Groq LPUs. GroqRack™ Cluster On-prem Al inference for your data center, powered by Groq LPUs. Enterprise Arrow pointing down Contact Sales Developers Arrow pointing down Free API key Quickstart Community Demos Resources Arrow pointing down Blog Case Studies News Videos Whitepapers Pricing About Arrow pointing down About Groq Announcements Team Careers News Contact Us Start Building Menu Toggle Main Navigation Close icon Close mobile navigation Products Arrow pointing down Products Overview GroqCloud™ Platform Fast, affordable Al inference on-demand, powered by Groq LPUs. GroqRack™ Cluster On-prem Al inference for your data center, powered by Groq LPUs. Enterprise Arrow pointing down Contact Sales Developers Arrow pointing down Free API key Quickstart Community Demos Resources Arrow pointing down Blog Case Studies News Videos Whitepapers Pricing About Arrow pointing down About Groq Announcements Team Careers News Contact Us Groq Community Discord Twitter YouTube Thread LinkedIn Instagram Resources For general press inquiries, reach out to our PR team . Case Studies Blog Whitepapers Videos Announcements News 08/01/2025 Inside the LPU: Deconstructing Groq’s Speed 07/31/2025 OpenBench: Open, Reproducible Evals 06/16/2025 Build Faster with Groq + Hugging Face 06/10/2025 GroqCloud™ Now Supports Qwen3 32B 06/03/2025 Introducing GroqCloud™ LoRA Fine-Tune Support: Unlock Efficient Model Adaptation for Enterprises 05/27/2025 From Speed to Scale: How Groq Is Optimized for MoE & Other Large Models 05/16/2025 How to Build Your Own AI Research Agent with One Groq API Call 04/29/2025 The Official Llama API, Accelerated by Groq 04/15/2025 Now in Preview: Groq’s First Compound AI System 04/05/2025 Llama 4 Live Today on Groq — Build Fast at the Lowest Cost, Without Compromise 03/26/2025 Build Fast with Text-to-Speech 03/18/2025 Groq & Vercel Partner To Make Building Fast and Simple 03/13/2025 Batch Processing with GroqCloud™ for AI Inference Workloads 03/13/2025 Build Fast with Word-Level Timestamping 03/08/2025 A Guide to Reasoning with Qwen QwQ 32B 03/07/2025 What is a Language Processing Unit? 03/05/2025 Qwen QwQ 32B Running Same Day As Release 03/01/2025 Thank You! 1 Million Developers Now On GroqCloud™ 02/28/2025 How to Win Hackathons with Groq 02/26/2025 Mistral Saba Added to GroqCloud™ Model Suite 02/11/2025 GroqCloud™ Now Offers qwen-2.5-32b and deepseek-r1-distill-qwen-32b 02/10/2025 GroqCloud™ Developer Tier Self-serve Access Now Available 02/10/2025 Saudi Arabia Announces $1.5 Billion Expansion to Fuel AI-powered Economy with Groq 01/28/2025 GroqCloud™ Makes DeepSeek R1 Distill Llama 70B Available 01/24/2025 Largest, Most Capable ASR Model Now Faster on GroqCloud™ 12/12/2024 Understanding AI 101: What is Inference in Machine Learning and AI Applications? 12/06/2024 A New Scaling Paradigm: Meta's Llama 3.3 70B Challenges \"Death of Scaling Law\" 12/06/2024 New AI Inference Speed Benchmark for Llama 3.3 70B, Powered by Groq 11/15/2024 Groq First Generation 14nm Chip Just Got a 6x Speed Boost: Introducing Llama 3.3 70B Speculative Decoding on GroqCloud™ 11/06/2024 The Five Future Stages of Generative AI 10/21/2024 The Crucial Role of Context Length in Large Language Models for Business Applications 10/09/2024 Whisper",
  "DeepSeek R1 Distill Llama 70B Available 01/24/2025 Largest, Most Capable ASR Model Now Faster on GroqCloud™ 12/12/2024 Understanding AI 101: What is Inference in Machine Learning and AI Applications? 12/06/2024 A New Scaling Paradigm: Meta's Llama 3.3 70B Challenges \"Death of Scaling Law\" 12/06/2024 New AI Inference Speed Benchmark for Llama 3.3 70B, Powered by Groq 11/15/2024 Groq First Generation 14nm Chip Just Got a 6x Speed Boost: Introducing Llama 3.3 70B Speculative Decoding on GroqCloud™ 11/06/2024 The Five Future Stages of Generative AI 10/21/2024 The Crucial Role of Context Length in Large Language Models for Business Applications 10/09/2024 Whisper Large v3 Turbo Now Available on Groq, Combining Speed & Quality for Speech Recognition 09/25/2024 Meta and Groq Continue To Build Open-source Developer Ecosystem as Llama 3.2 Launches 09/12/2024 Unleashing the Power of Fast AI Inference: Groq and Aramco Digital Partner to Establish World-leading Data Center 09/03/2024 Introducing LLaVA V1.5 7B on GroqCloud 08/20/2024 Distil-Whisper is Now Available to the Developer Community on GroqCloud™ for Faster and More Efficient Speech Recognition 08/09/2024 Insights from VB Transform 2024 with Jonathan Ross, Groq CEO & Founder 07/23/2024 Llama 3.1 by Meta Now Available on Groq 07/16/2024 Introducing Llama-3-Groq-Tool-Use Models 06/24/2024 Groq Runs Whisper Large V3 at a 164x Speed Factor According to New Artificial Analysis Benchmark 04/20/2024 12 Hours Later, Groq Deploys Llama 3 Instruct (8 & 70B) by Meta AI on Its LPU™ Inference Engine 03/25/2024 What NVIDIA Didn’t Say 03/11/2024 Groundbreaking Gemma 7B Performance Running on the Groq LPU™ Inference Engine 02/08/2024 ArtificialAnalysis.ai LLM Benchmark Doubles Axis To Fit New Groq LPU™ Inference Engine Performance Results 01/11/2024 Groq LPU™ Inference Engine Crushes First Public LLM Benchmark 01/03/2024 Retrieval Augmented Generation with Groq API 11/09/2023 HumanPlus: The Co-evolution of AI & Human Potential 07/28/2023 Every. Word. Matters. 03/09/2023 Automated Discovery Meets Automated Compilation 12/16/2021 Groq Accelerates COVID Drug Discovery by 333x for Argonne National Lab 04/14/2021 Brave Thinking 10/22/2019 Why AI Requires a New Chip Architecture 10/21/2019 World, Meet Groq Groq Groq was established in 2016 for one thing: inference. Products Pricing Products Overview GroqCloud™ Platform GroqRack™ Cluster Enterprise Enterprise Access Developers Free API Key Start Building Groq Libraries Demos Resources Blog Case Studies News Videos Whitepapers About About Groq Announcements Team Careers News Contact Us Terms & Policies Privacy Policy Trust Center Terms of Use GroqCloud Terms Security Trademark Policy Cookie Policy © 2025 Groq, Inc. , All rights reserved. Groq Community Discord Twitter YouTube Thread LinkedIn Instagram",
  "Groq Community Discord Twitter YouTube Thread LinkedIn Instagram",
  "Case Studies | Groq is fast inference for AI builders skip to content Groq Products Arrow pointing down Products Overview GroqCloud™ Platform Fast, affordable Al inference on-demand, powered by Groq LPUs. GroqRack™ Cluster On-prem Al inference for your data center, powered by Groq LPUs. Enterprise Arrow pointing down Contact Sales Developers Arrow pointing down Free API key Quickstart Community Demos Resources Arrow pointing down Blog Case Studies News Videos Whitepapers Pricing About Arrow pointing down About Groq Announcements Team Careers News Contact Us Start Building Menu Toggle Main Navigation Close icon Close mobile navigation Products Arrow pointing down Products Overview GroqCloud™ Platform Fast, affordable Al inference on-demand, powered by Groq LPUs. GroqRack™ Cluster On-prem Al inference for your data center, powered by Groq LPUs. Enterprise Arrow pointing down Contact Sales Developers Arrow pointing down Free API key Quickstart Community Demos Resources Arrow pointing down Blog Case Studies News Videos Whitepapers Pricing About Arrow pointing down About Groq Announcements Team Careers News Contact Us Groq Community Discord Twitter YouTube Thread LinkedIn Instagram Resources For general press inquiries, reach out to our PR team . Case Studies Blog Whitepapers Videos Announcements News PGA of America: Transforming Operations with Faster, Smarter AI Enabling LLMOps with Fast AI Inference AI-powered Financial Insights Ideation and Animation at Human Speed Powering Inbound Call Success with AI Bringing AI-powered Robots to Everyone Real-time Inference for the Real World How Real-time Inference Lets Customers Talk to Their Data Revolutionizing the AI Shopping Assistant Experience AI-powered Spreadsheets for a New Era of Data Analysis Powering More Creative and Productive Business Teams with AI Real-time Inference for the Real World Groq Groq was established in 2016 for one thing: inference. Products Pricing Products Overview GroqCloud™ Platform GroqRack™ Cluster Enterprise Enterprise Access Developers Free API Key Start Building Groq Libraries Demos Resources Blog Case Studies News Videos Whitepapers About About Groq Announcements Team Careers News Contact Us Terms & Policies Privacy Policy Trust Center Terms of Use GroqCloud Terms Security Trademark Policy Cookie Policy © 2025 Groq, Inc. , All rights reserved. Groq Community Discord Twitter YouTube Thread LinkedIn Instagram"
]